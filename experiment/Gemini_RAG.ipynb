{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "key = os.getenv(\"GEMINI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import warnings\n",
    "from pathlib import Path as p\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=key,\n",
    "                             temperature=0.3,convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(r\"C:\\Users\\jay59\\Downloads\\AI_A_Modern_Approach_3rdEd.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = pdf_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preface ix\n",
      "•instructions on how to contact the authors with questions or comments,\n",
      "•instructions on how to report errors in the book, in the likely event that some exist, and\n",
      "•slides and other materials for instructors.\n",
      "About the cover\n",
      "The cover depicts the ﬁnal position from the decisive game 6 of the 1997 match between\n",
      "chess champion Garry Kasparov and program D EEPBLUE. Kasparov, playing Black, was\n",
      "forced to resign, making this the ﬁrst time a computer had beaten a world champion in achess match. Kasparov is shown at the top. To his left is the Asimo humanoid robot andto his right is Thomas Bayes (1702–1761), whose ideas about probability as a measure ofbelief underlie much of modern AI technology. Below that we see a Mars Exploration Rover,a robot that landed on Mars in 2004 and has been exploring the planet ever since. To theright is Alan Turing (1912–1954), whose fundamental work deﬁned the ﬁelds of computerscience in general and artiﬁcial intelligence in particular. At the bottom is Shakey (1966–1972), the ﬁrst robot to combine perception, world-modeling, planning, and learning. WithShakey is project leader Charles Rosen (1917–2002). At the bottom right is Aristotle (384\n",
      "B.C.–322 B.C.), who pioneered the study of logic; his work was state of the art until the 19th\n",
      "century (copy of a bust by Lysippos). At the bottom left, lightly screened behind the authors’names, is a planning algorithm by Aristotle from De Motu Animalium in the original Greek.\n",
      "Behind the title is a portion of the CPSC Bayesian network for medical diagnosis (Pradhanet al., 1994). Behind the chess board is part of a Bayesian logic model for detecting nuclear\n",
      "explosions from seismic signals.\n",
      "Credits: Stan Honda/Getty (Kasparaov), Library of Congress (Bayes), NASA (Mars\n",
      "rover), National Museum of Rome (Aristotle), Peter Norvig (book), Ian Parker (Berkeleyskyline), Shutterstock (Asimo, Chess pieces), Time Life/Getty (Shakey, Turing).\n",
      "Acknowledgments\n",
      "This book would not have been possible without the many contributors whose names did notmake it to the cover. Jitendra Malik and David Forsyth wrote Chapter 24 (computer vision)and Sebastian Thrun wrote Chapter 25 (robotics). Vibhu Mittal wrote part of Chapter 22(natural language). Nick Hay, Mehran Sahami, and Ernest Davis wrote some of the exercises.Zoran Duric (George Mason), Thomas C. Henderson (Utah), Leon Reznik (RIT), MichaelGourley (Central Oklahoma) and Ernest Davis (NYU) reviewed the manuscript and madehelpful suggestions. We thank Ernie Davis in particular for his tireless ability to read multipledrafts and help improve the book. Nick Hay whipped the bibliography into shape and ondeadline stayed up to 5:30 AM writing code to make the book better. Jon Barron formattedand improved the diagrams in this edition, while Tim Huang, Mark Paskin, and CynthiaBruyns helped with diagrams and algorithms in previous editions. Ravi Mohan and Ciaran\n",
      "O’Reilly wrote and maintain the Java code examples on the Web site. John Canny wrote\n",
      "the robotics chapter for the ﬁrst edition and Douglas Edwards researched the historical notes.Tracy Dunkelberger, Allison Michael, Scott Disanno, and Jane Bonnell at Pearson tried theirbest to keep us on schedule and made many helpful suggestions. Most helpful of all has\n"
     ]
    }
   ],
   "source": [
    "print(pages[8].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1216"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
    "context = \"\\n\\n\".join(str(p.page_content) for p in pages)\n",
    "texts = text_splitter.split_text(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artiﬁcial Intelligence\n",
      "A Modern Approach\n",
      "Third Edition\n",
      "\n",
      "PRENTICE HALL SERIES\n",
      "IN ARTIFICIAL INTELLIGENCE\n",
      "Stuart Russell and Peter Norvig, Editors\n",
      "FORSYTH &P ONCE Computer Vision: A Modern Approach\n",
      "GRAHAM ANSI Common Lisp\n",
      "JURAFSKY &M ARTIN Speech and Language Processing, 2nd ed.\n",
      "NEAPOLITAN Learning Bayesian Networks\n",
      "RUSSELL &N ORVIG Artiﬁcial Intelligence: A Modern Approach, 3rd ed.\n",
      "\n",
      "Artiﬁcial Intelligence\n",
      "A Modern Approach\n",
      "Third Edition\n",
      "Stuart J. Russell and Peter Norvig\n",
      "Contributing writers :\n",
      "Ernest Davis\n",
      "Douglas D. Edwards\n",
      "David Forsyth\n",
      "Nicholas J. Hay\n",
      "Jitendra M. Malik\n",
      "Vibhu Mittal\n",
      "Mehran Sahami\n",
      "Sebastian Thrun\n",
      "Upper Saddle River Boston Columbus San Francisco New York\n",
      "Indianapolis London Toronto Sydney Singapore Tokyo Montreal\n",
      "Dubai Madrid Hong Kong Mexico City Munich Paris Amsterdam Cape Town\n",
      "\n",
      "Vice President and Editorial Director, ECS: Marcia J. Horton\n",
      "Editor-in-Chief: Michael Hirsch\n",
      "Executive Editor: Tracy Dunkelberger\n",
      "Assistant Editor: Melinda Haggerty\n",
      "Editorial Assistant: Allison Michael\n",
      "Vice President, Production: Vince O’BrienSenior Managing Editor: Scott Disanno\n",
      "Production Editor: Jane Bonnell\n",
      "Senior Operations Supervisor: Alan FischerOperations Specialist: Lisa McDowell\n",
      "Marketing Manager: Erin Davis\n",
      "Marketing Assistant: Mack Patterson\n",
      "Cover Designers: Kirsten Sims and Geoffrey Cassar\n",
      "Cover Images: Stan Honda/Getty, Library of Congress, NASA, National Museum of Rome,\n",
      "Peter Norvig, Ian Parker, Shutterstock, Time Life/Getty\n",
      "Interior Designers: Stuart Russell and Peter Norvig\n",
      "Copy Editor: Mary Lou NohrArt Editor: Greg Dulles\n",
      "Media Editor: Daniel Sandin\n",
      "Media Project Manager: Danielle Leone\n",
      "Copyright c⃝2010, 2003, 1995 by Pearson Education, Inc.,\n",
      "Upper Saddle River, New Jersey 07458.\n",
      "All rights reserved. Manufactured in the United States of America. This publication is protected byCopyright and permissions should be obtained from the publisher prior to any prohibited reproduction,\n",
      "storage in a retrieval system, or transmission in any form or by any means, electronic, mechanical,\n",
      "photocopying, recording, or likewise. To obtain permission(s) to use materials from this work, please\n",
      "submit a written request to Pearson Higher Education, Permissions Department, 1 Lake Street, Upper\n",
      "Saddle River, NJ 07458.\n",
      "The author and publisher of this book have used their best efforts in preparing this book. These\n",
      "efforts include the development, research, and tes ting of the theories and programs to determine their\n",
      "effectiveness. The author and publisher make no warranty of any kind, expressed or implied, with\n",
      "regard to these programs or the documentation contained in this book. The author and publisher shall\n",
      "not be liable in any event for incidental or consequential damages in connection with, or arising out\n",
      "of, the furnishing, performance, or use of these programs.\n",
      "Library of Congress Cataloging-in-Publication Data on File\n",
      "1 0987654321\n",
      "ISBN-13: 978-0-13-604259-4ISBN-10: 0-13-604259-7\n",
      "\n",
      "For Loy, Gordon, Lucy, George, and Isaac — S.J.R.\n",
      "For Kris, Isabella, and Juliet —P . N .\n",
      "\n",
      "This page intentionally left blank\n",
      "\n",
      "Preface\n",
      "Artiﬁcial Intelligence (AI) is a big ﬁeld, and this is a big book. We have tried to explore the\n",
      "full breadth of the ﬁeld, which encompasses logic, probability, and continuous mathematics;perception, reasoning, learning, and action; and everything from microelectronic devices to\n",
      "robotic planetary explorers. The book is also big because we go into some depth.\n",
      "The subtitle of this book is “A Modern Approach.” The intended meaning of this rather\n",
      "empty phrase is that we have tried to synthesize what is now known into a common frame-work, rather than trying to explain each subﬁeld of AI in its own historical context. Weapologize to those whose subﬁelds are, as a result, less recognizable.\n",
      "New to this edition\n",
      "This edition captures the changes in AI that have taken place since the last edition in 2003.There have been important applications of AI technology, such as the widespread deploy-ment of practical speech recognition, machine translation, autonomous vehicles, and house-hold robotics. There have been algorithmic landmarks, such as the solution of the game ofcheckers. And there has been a great deal of theoretical progress, particularly in areas such\n",
      "as probabilistic reasoning, machine learning, and computer vision. Most important from our\n",
      "point of view is the continued evolution in how we think about the ﬁeld, and thus how weorganize the book. The major changes are as follows:\n",
      "•We place more emphasis on partially observable and nondeterministic environments,\n",
      "especially in the nonprobabilistic settings of search and planning. The concepts ofbelief state (a set of possible worlds) and state estimation (maintaining the belief state)\n",
      "are introduced in these settings; later in the book, we add probabilities.\n",
      "•In addition to discussing the types of environments and types of agents, we now cover\n",
      "in more depth the types of representations that an agent can use. We distinguish among\n",
      "atomic representations (in which each state of the world is treated as a black box),\n",
      "factored representations (in which a state is a set of attribute/value pairs), and structured\n",
      "representations (in which the world consists of objects and relations between them).\n",
      "•Our coverage of planning goes into more depth on contingent planning in partially\n",
      "observable environments and includes a new approach to hierarchical planning.\n",
      "•We have added new material on ﬁrst-order probabilistic models, including open-universe\n",
      "models for cases where there is uncertainty as to what objects exist.\n",
      "•We have completely rewritten the introductory machine-learning chapter, stressing a\n",
      "wider variety of more modern learning algorithms and placing them on a ﬁrmer theo-retical footing.\n",
      "•We have expanded coverage of Web search and information extraction, and of tech-\n",
      "niques for learning from very large data sets.\n",
      "•20% of the citations in this edition are to works published after 2003.\n",
      "•We estimate that about 20% of the material is brand new. The remaining 80% reﬂects\n",
      "older work but has been largely rewritten to present a more uniﬁed picture of the ﬁeld.\n",
      "vii\n",
      "\n",
      "viii Preface\n",
      "Overview of the book\n",
      "The main unifying theme is the idea of an intelligent agent . We deﬁne AI as the study of\n",
      "agents that receive percepts from the environment and perform actions. Each such agent im-\n",
      "plements a function that maps percept sequences to actions, and we cover different ways torepresent these functions, such as reactive agents, real-time planners, and decision-theoreticsystems. We explain the role of learning as extending the reach of the designer into unknownenvironments, and we show how that role constrains agent design, favoring explicit knowl-edge representation and reasoning. We treat robotics and vision not as independently deﬁnedproblems, but as occurring in the service of achieving goals. We stress the importance of thetask environment in determining the appropriate agent design.\n",
      "Our primary aim is to convey the ideas that have emerged over the past ﬁfty years of AI\n",
      "research and the past two millennia of related work. We have tried to avoid excessive formal-ity in the presentation of these ideas while retaining precision. We have included pseudocode\n",
      "algorithms to make the key ideas concrete; our pseudocode is described in Appendix B.\n",
      "This book is primarily intended for use in an undergraduate course or course sequence.\n",
      "The book has 27 chapters, each requiring about a week’s worth of lectures, so workingthrough the whole book requires a two-semester sequence. A one-semester course can useselected chapters to suit the interests of the instructor and students. The book can also beused in a graduate-level course (perhaps with the addition of some of the primary sourcessuggested in the bibliographical notes). Sample syllabi are available at the book’s Web site,aima.cs.berkeley.edu . The only prerequisite is familiarity with basic concepts of\n",
      "computer science (algorithms, data structures, complexity) at a sophomore level. Freshman\n",
      "calculus and linear algebra are useful for some of the topics; the required mathematical back-ground is supplied in Appendix A.\n",
      "Exercises are given at the end of each chapter. Exercises requiring signiﬁcant pro-\n",
      "gramming are marked with a keyboard icon. These exercises can best be solved by taking\n",
      "advantage of the code repository at aima.cs.berkeley.edu . Some of them are large\n",
      "enough to be considered term projects. A number of exercises require some investigation of\n",
      "the literature; these are marked with a book icon.\n",
      "Throughout the book, important points are marked with a pointing icon. We have in-\n",
      "cluded an extensive index of around 6,000 items to make it easy to ﬁnd things in the book.\n",
      "Wherever a new term is ﬁrst deﬁned, it is also marked in the margin. NEW TERM\n",
      "About the Web site\n",
      "aima.cs.berkeley.edu , the Web site for the book, contains\n",
      "•implementations of the algorithms in the book in several programming languages,\n",
      "•a list of over 1000 schools that have used the book, many with links to online course\n",
      "materials and syllabi,\n",
      "•an annotated list of over 800 links to sites around the Web with useful AI content,\n",
      "•a chapter-by-chapter list of supplementary material and links,\n",
      "•instructions on how to join a discussion group for the book,\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = Chroma.from_texts(texts, embeddings).as_retriever(search_kwargs={\"k\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    model,\n",
    "    retriever=vector_index,\n",
    "    return_source_documents=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Explain the concept of reinforcement learning and its use in training artificial intelligence agents.\"\n",
    "result = qa_chain({\"query\": question})\n",
    "ans = result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinforcement learning is a type of machine learning that allows an agent to learn how to behave in an environment by interacting with it and receiving rewards or punishments for its actions. The agent learns to associate certain actions with positive outcomes and other actions with negative outcomes, and it adjusts its behavior accordingly.\n",
      "\n",
      "Reinforcement learning is often used in training artificial intelligence agents, such as those used in video games or robotics. By allowing the agent to learn from its own experiences, reinforcement learning can help it to develop more effective strategies for achieving its goals.\n",
      "\n",
      "One of the key challenges in reinforcement learning is the exploration-exploitation tradeoff. The agent must balance the need to explore new actions and learn about the environment with the need to exploit its current knowledge to maximize its rewards. If the agent explores too much, it may never learn the optimal policy for the environment. If it exploits too much, it may miss out on opportunities to improve its policy.\n",
      "\n",
      "There are a number of different reinforcement learning algorithms that can be used to train agents. Some of the most common algorithms include:\n",
      "\n",
      "* **Q-learning:** Q-learning is a value-based reinforcement learning algorithm that estimates the value of each state-action pair. The agent then uses these values to select the action that is expected to maximize its long-term reward.\n",
      "* **SARSA:** SARSA is a variant of Q-learning that uses a different update rule. SARSA is often used in situations where the environment is partially observable.\n",
      "* **Policy gradients:** Policy gradient methods are a class of reinforcement learning algorithms that directly optimize the policy function. Policy gradient methods are often used in situations where the state space is large or continuous.\n",
      "\n",
      "Reinforcement learning is a powerful tool that can be used to train agents to solve a wide variety of problems. However, it is important to understand the challenges involved in reinforcement learning, such as the exploration-exploitation tradeoff, in order to use it effectively.\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
